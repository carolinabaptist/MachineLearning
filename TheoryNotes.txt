Learning: any process by which a system improves its performance from experience

Artificial Intelligence: Encompasses all techniques and technologies that allow machines 
to perform intelligent tasks. Includes: Machine Learning, Natural Language Processing, 
Computer Vision, Robotics, Expert Systems, among others.

Machine Learning: field of study that focuses on developing algorithms and models that allow 
computers to learn from data and improve their performance on specific tasks with experience.

Data Science: Art of discovering implicit, previously unknown, and potentially useful 
knowledge from data. Machine Learning is a tool within data science. Combines statistics, 
data analysis, machine learning and other techniques to extract knowledge and insights from data.

Types of Machine Learning

Supervised Learning: The system learns from a training data set that includes the desired inputs 
and outputs (labels). The goal is to create a model that can predict the correct output for new 
inputs. Examples: Classifying emails as spam or non-spam, recognizing handwritten digits.

Unsupervised Learning: The system learns from input data without output labels. 
The goal is to find patterns or structure in the data. Examples: Grouping customers based on 
purchasing behavior, dimensionality reduction.

Reinforcement Learning:The system learns through interactions with an environment. You receive 
rewards or penalties based on the actions you take and adjust your behavior to maximize the total 
reward. Examples: Video games, robotics.

Traditional Programming: It involves writing programs explicitly to solve problems. Each step of 
the process is detailed by the programmer. Explicit instructions written by the programmer. 
Performance and accuracy depend on the quality of the instructions provided.

Classical AI: Based on heuristics and symbolic logic, where knowledge is encoded in explicit rules
and representations.

Machine Learning: Learning algorithms that find patterns in data and adjust models based on 
those patterns. The ouput is a learned model that can make predictions or decisions based on 
new data. Performance and accuracy depend on the quantity and quality of the data and the 
learning algorithm.

When to use ML:

1)In unknown or previously unexplored environments, such as the surface of Mars, there is no 
direct human expertise that can be applied. ML algorithms can be trained to identify patterns
and make data-driven decisions.

2)When Humans Can't Explain Their Expertise. Example: Recognizing speech patterns and human 
accents is something we do naturally, but it is difficult to explain all the details of how it
is done.

3)When Models Need to Be Customized. Example:ML can be used to create models that take into 
account patient-specific data (medical history, genomics, etc.) to recommend personalized 
treatments that maximize effectiveness and minimize side effects.

Machine Learning Terminology

Dataset: collection of observations or instances. Each observation can be described by several characteristics or attributes (also called variables or features).
Observations/Instances/Records: Each row in a dataset represents an observation, instance, or record.
Variables/Attributes:They are characteristics or properties that describe the observations in the data set. They can be input (input) or output (output).

Data Size: Refers to the total number of observations in the data set.
Data Dimensionality: Refers to the number of variables or attributes in the dataset.
Features: individual variables that are used as inputs to the model.

Numeric Variables
Discrete Variables: Variables that take on finite values. Do not have fractional values.
Continuous Variables: can take on any value within a range. Include fractions and decimals.

Categorical Variables
Nominal Variables: Categorical variables that do not have an intrinsic order.
Ordinal Variables: Categorical variables that have an intrinsic order. Example: clothing sizes (small, medium, large)

Empirical Distribution: It is the representation of data collected from a specific set of observations.
Theoretical Distribution: A theoretical distribution is a mathematical function that describes the expected behavior of a variable. 

Mean: sum of all values ‚Äã‚Äãin a data set divided by the total number of values.
Median: is the value that divides an ordered set of data into two equal halves. 
If the number of observations is odd, the median is the middle value. If it is even, it is the average of the two central values.
Mode: the value that appears most frequently in a data set.

Standard Deviation: measures the amount of variation of a set of values. A low standard deviation indicates that values ‚Äã‚Äãtend to be close to the mean, while a high standard deviation indicates that values ‚Äã‚Äãare spread over a wider range.
Percentiles: values ‚Äã‚Äãthat divide a set of data into 100 equal parts. The 50th percentile is the median.
25th Percentile (First Quartile): 25% of the data is less than or equal to this value.
75th Percentile (Third Quartile): 75% of the data is less than or equal to this value.

IQR - Interquartile Range: the difference between the third quartile (Q3) and the first quartile (Q1).The IQR is widely used to identify outliers outside [q1 -1.5 * IQR, q3 + 1.5*IQR].
Correlation: measures the strength and direction of the linear relationship between two numeric variables.Pearson Correlation Coefficient and Spearman Coefficient are commonly used.

Data Visualization

Histogram: graphical representation of the distribution of a set of numerical data. It is used to visualize the frequency distribution of values ‚Äã‚Äãin continuous or discrete intervals.

Horizontal Axis (X): Represents the ranges (or "bins") into which data is grouped. Each interval covers a range of values ‚Äã‚Äãfrom the dataset.
Vertical Axis (Y): Represents the frequency (the number of occurrences) of data within each interval.

Example: Annual salaries of a group of 1000 employees in a company. Divide the salary range into bins and see the number of employees in each range.

Boxplot: graphical tool used to summarize the distribution of a set of quantitative (numeric) data. It shows the median, quartiles, and possible outliers in a visually intuitive way.
  o   Outlier      
__|__ Upper Limit
|    |Upper Quartile (Q3): 75th percentile
|____|Median (Q2): 50th percentile
|____|Lower Quartile (Q1): 25th percentile.
   |  Lower limit
   o  Outlier

The height of the box represents the interquartile range (IQR), which is Q3 - Q1.
The whiskers extend from the quartiles to the boundaries defined as:
Lower Limit: Q1 - 1.5 * IQR.
Upper Limit: Q3 + 1.5 * IQR.
Outliers: Data points that are outside the bounds of the whiskers. They are plotted individually.

Vector Space (or Feature Space): A feature is a measurable characteristic of a phenomenon. Features are usually numeric or categorical, but can also be structural such as images, videos, time series or graphs. A phenomenon is described by random variables.

Random variable: function that associates each result of a random experiment with a numerical value. It quantitatively represents the possible results of an uncertain phenomenon.

Types of random variable: Discrete and Continuous.

Examples of Vector Space:

1) Euclidean Vector Space R^2: It is a two-dimensional vector space where each point is represented by an ordered pair of real numbers (x, y). For example, the Cartesian plane. Each point on the plane is a vector. ùë£ = (3,4) is a vector at ùëÖ2.

2) Euclidean Vector Space R^3: It is a three-dimensional vector space where each point is represented by an ordered trio of real numbers (x, y, z). The three-dimensional space we use to represent physical positions. A vector in this space can be 
w=(1,2,3).

Univariate Data Space: a set of observations of a single variable. Each observation can be represented by a numerical value. Suppose we are measuring the height of a group of people. Heights are represented as a list of values: [170,165,180,175,160].

Descriptive Statistics: Mean, median, mode, variance, standard deviation.
Visualization: Histograms, box plots.

Multivariate Data Space: set of observations of multiple variables. Each observation is represented by a vector of numerical values, where each component of the vector corresponds to a variable. Example: Each person is represented by a vector (height, weight, age):(170,70,25)

Multivariate Descriptive Statistics: Mean and variance for each variable, covariance between variables.

Variance: quantifies how much the values ‚Äã‚Äãin a data set differ from the average of those values.

Visualization: Scatter plots, scatter matrices, correlation graphs.

Scatter plot: used to visualize the relationship between two numerical variables. Each point on the graph represents a pair of values. 
If the points form an ascending line, it indicates a positive correlation. 
If the points form a descending line, it indicates a negative correlation.
If the points are randomly scattered, it indicates little or no correlation.
It is useful to identify patterns, trends, correlations between two variables and possible outliers.

Scatter Matrix: collection of scatter plots organized in a matrix. Each graph in the matrix shows the relationship between a different pair of variables. is useful for viewing relationships between multiple variables at the same time.

Correlation graphs: matrix where each cell shows the correlation coefficient between a pair of variables. Correlation values ‚Äã‚Äãrange from -1 to 1. Cells are often colored to help visualize strong and weak correlations.
1: perfect positive correlation.
-1: perfect negative correlation.
0: no linear correlation.

Multivariate methods: statistical techniques that analyze data involving multiple variables at the same time. Main Multivariate Methods:

1) Principal component analysis (PCA): dimensionality reduction technique that transforms a set of correlated variables into a set of uncorrelated variables, called principal components.

2) Clustering: unsupervised machine learning technique that involves grouping a set of objects in such a way that objects in the same group (or cluster) are more similar to each other than to those in other groups.

3) Linear Discriminant Analysis (LDA): seeks to project data into a lower-dimensional space in order to maximize the separation between different classes. Similar to Principal Component Analysis (PCA), LDA reduces the number of dimensions in the data. However, unlike PCA, LDA takes the data category into account when performing the reduction.

4) Multivariate regression: used to model the relationship between multiple independent variables (predictors) and one or more dependent variables (responses). 
  Multiple regression: There is only one dependent variable. 
  Multivariate regression: There is more than one dependent variable.

Minkowski Distances: family of metrics used to measure the distance between points in a vector space. Consider x = (x1, x2, ..., xn) and y = (y1,y2,...,yn) in a n-dimensional space:

d(x,y) = (sum(|xi-yi|^p)) ^ 1/p
*sum from i to n
p is a parameter that defines the specific metric.
Manhattan Distance (or L1 Norm): p = 1
Euclidean Distance (or L2 Norm): p = 2
